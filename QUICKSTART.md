# üöÄ Quick Start - BookNLP GPU Service

## –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# 1. –°–∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
cd /opt/gstory/booknlp-gateway

# 2. –°–æ–∑–¥–∞–π—Ç–µ .env —Ñ–∞–π–ª
cp .env.example .env

# 3. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª—è–º (–≤–∞–∂–Ω–æ!)
nano .env
```

**–í–∞–∂–Ω–æ –≤ .env:**
```bash
# –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –≥–¥–µ —Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ —Ö–æ—Å—Ç–µ
MODELS_PATH=/opt/booknlp-models  # –ò–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –ø—É—Ç—å

# –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
BOOKNLP_MODEL=big  # –∏–ª–∏ small
```

## –®–∞–≥ 2: –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏

```bash
# –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É –¥–ª—è –º–æ–¥–µ–ª–µ–π
mkdir -p ${MODELS_PATH}  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ .env

# –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
mkdir -p data temp
```

## –®–∞–≥ 3: –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–∏—Å

```bash
# –°–æ–±–µ—Ä–∏—Ç–µ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ
docker compose up -d

# –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ª–æ–≥–∞–º–∏
docker compose logs -f

# –î–æ–∂–¥–∏—Ç–µ—Å—å —Å–æ–æ–±—â–µ–Ω–∏—è: "Application startup complete"
```

## –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞
curl http://localhost:8888/health

# –î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ:
# {
#   "status": "healthy",
#   "cuda_available": true,
#   "gpu_count": 1,
#   "gpu_name": "NVIDIA GeForce RTX 3090"
# }
```

## –®–∞–≥ 5: –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å

```bash
curl -X POST http://localhost:8888/extract \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Frodo Baggins was a hobbit who lived in the Shire. He had a friend named Samwise Gamgee.",
    "book_id": "test"
  }'
```

## üì° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–∑ gstory (LXC)

–í gstory —Å–æ–∑–¥–∞–π—Ç–µ –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Å–≤—è–∑–∏ —Å GPU —Å–µ—Ä–≤–∏—Å–æ–º:

```python
# –í LXC: src/gstory/extractors/remote_booknlp.py
import requests

class RemoteBookNLPClient:
    def __init__(self, host_url: str = "http://YOUR_HOST_IP:8888"):
        self.base_url = host_url

    def extract(self, text: str, book_id: str) -> dict:
        response = requests.post(
            f"{self.base_url}/extract",
            json={"text": text, "book_id": book_id},
            timeout=3600  # 1 hour timeout
        )
        response.raise_for_status()
        return response.json()

    def health(self) -> dict:
        response = requests.get(f"{self.base_url}/health")
        response.raise_for_status()
        return response.json()
```

## üîß –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–æ–º

```bash
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
docker-compose down

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å
docker-compose restart

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ª–æ–≥–∏
docker-compose logs -f

# –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–¥
docker-compose up -d --build

# –ó–∞–π—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
docker-compose exec booknlp-gpu bash
```

## ‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- **Big model –Ω–∞ RTX 3090**: ~2 –º–∏–Ω / 100K tokens
- **Small model –Ω–∞ CPU**: ~15 –º–∏–Ω / 100K tokens
- **–£—Å–∫–æ—Ä–µ–Ω–∏–µ**: ~7.5x

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏

```
/opt/gstory/booknlp-gateway/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ booknlp_test/
‚îÇ       ‚îú‚îÄ‚îÄ test.tokens
‚îÇ       ‚îú‚îÄ‚îÄ test.entities
‚îÇ       ‚îú‚îÄ‚îÄ test.quotes
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ models/  (—Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ —Å —Ö–æ—Å—Ç–∞)
‚îî‚îÄ‚îÄ temp/
```

## üêõ Troubleshooting

### GPU –Ω–µ –≤–∏–¥–Ω–∞
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ NVIDIA runtime
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –Ω–∞ –ø–∞–ø–∫—É –º–æ–¥–µ–ª–µ–π
ls -la ${MODELS_PATH}

# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø–∞–ø–∫–∞ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞
docker-compose exec booknlp-gpu ls -la /models
```

### –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏
```bash
docker-compose logs -f --tail=100
```
